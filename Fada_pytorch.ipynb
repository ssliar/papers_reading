{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fada implemention in pytorch\n",
    "* papers:Few-Shot Domain Adaptation (https://arxiv.org/abs/1711.02536)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入相关的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义相关的参数（训练）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y):\n",
    "    return (torch.max(y_pred, 1)[1] == y).float().mean().data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eval_on_test\n",
    "* Returns the mean accuracy on the test set, given a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test(test_dataloader, model_fn):\n",
    "    acc = 0\n",
    "    for x, y in test_dataloader:\n",
    "        x, y = Variable(x), Variable(y)\n",
    "        if torch.cuda.is_available():\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        acc += accuracy(model_fn(x), y)\n",
    "    return round(acc / float(len(test_dataloader)), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### into_tensor\n",
    "* Converts a list of (x, x) pairs into two Tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def into_tensor(data, into_vars=True):\n",
    "    X1 = [x[0] for x in data]\n",
    "    X2 = [x[1] for x in data]\n",
    "    if torch.cuda.is_available():\n",
    "        return Variable(torch.stack(X1)).cuda(), Variable(torch.stack(X2)).cuda()\n",
    "    return Variable(torch.stack(X1)), Variable(torch.stack(X2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnist_dataloader\n",
    "* Returns the MNIST dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_dataloader(batch_size=256, train=True, cuda=False):\n",
    "    dataset = torchvision.datasets.MNIST('./data', download=True, train=train, transform=torchvision.transforms.ToTensor())\n",
    "    return torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=batch_size, num_workers=2, pin_memory=cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svhn_dataloaderabs\n",
    "* Returns the SVHN dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svhn_dataloader(batch_size=256, train=True, cuda=False):\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((28, 28)),\n",
    "        torchvision.transforms.Grayscale(),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "    dataset = torchvision.datasets.SVHN('./data', download=True, split=('train' if train else 'test'), transform=transform)\n",
    "    return torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=batch_size, num_workers=2, pin_memory=cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample_data\n",
    "* Samples a subset from source into memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(n=2000):\n",
    "    dataset = torchvision.datasets.MNIST('./data', download=True, train=True, transform=torchvision.transforms.ToTensor())\n",
    "    X = torch.FloatTensor(n, 1, 28, 28)\n",
    "    Y = torch.LongTensor(n)\n",
    "    inds = torch.randperm(len(dataset))[:n]\n",
    "    for i, index in enumerate(inds):\n",
    "        x, y = dataset[index]\n",
    "        X[i] = x\n",
    "        Y[i] = y\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_target_samples\n",
    "* Returns a subset of the target domain such that it has n_target_samples per class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_samples(n=1):\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((28, 28)),\n",
    "        torchvision.transforms.Grayscale(),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "    dataset = torchvision.datasets.SVHN('./data', download=True, split='train', transform=transform)\n",
    "    X, Y = [], []\n",
    "    classes = 10 * [n]\n",
    "    i = 0\n",
    "    while True:\n",
    "        if len(X) == n*10:\n",
    "            break\n",
    "        x, y = dataset[i]\n",
    "        if classes[y] > 0:\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "            classes[y] -= 1\n",
    "        i += 1\n",
    "    assert(len(X) == n*10)\n",
    "    return torch.stack(X), torch.from_numpy(np.array(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_groups\n",
    "*  Samples uniformly groups G1 and G3 from D_s x D_s and groups G2 and G4 from D_s x D_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groups(X_s, y_s, X_t, y_t):\n",
    "    n = X_t.shape[0]\n",
    "    G1, G3 = [], []\n",
    "    # TODO optimize\n",
    "    # Groups G1 and G3 come from the source domain\n",
    "    for i, (x1, y1) in enumerate(zip(X_s, y_s)):\n",
    "        for j, (x2, y2) in enumerate(zip(X_s, y_s)):\n",
    "            if y1 == y2 and i != j and len(G1) < n:\n",
    "                G1.append((x1, x2))\n",
    "            if y1 != y2 and i != j and len(G3) < n:\n",
    "                G3.append((x1, x2))\n",
    "    G2, G4 = [], []\n",
    "    # Groups G2 and G4 are mixed from the source and target domains\n",
    "    for i, (x1, y1) in enumerate(zip(X_s, y_s)):\n",
    "        for j, (x2, y2) in enumerate(zip(X_t, y_t)):\n",
    "            if y1 == y2 and i != j and len(G2) < n:\n",
    "                G2.append((x1, x2))\n",
    "            if y1 != y2 and i != j and len(G4) < n:\n",
    "                G4.append((x1, x2))\n",
    "    groups = [G1, G2, G3, G4]\n",
    "    # Make sure we sampled enough samples\n",
    "    for g in groups:\n",
    "        assert(len(g) == n)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample_groups\n",
    "*  Sample groups G1, G2, G3, G4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_groups(n_target_samples=2):\n",
    "    X_s, y_s = sample_data()\n",
    "    X_t, y_t = create_target_samples(n_target_samples)\n",
    "    print(\"Sampling groups\")\n",
    "    return create_groups(X_s, y_s, X_t, y_t), (X_s, y_s, X_t, y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Domain-Class Discriminator\n",
    "* Domain-Class Discriminator (see (3) in the paper) Takes in the concatenated latent representation of two samples from G1, G2, G3 or G4, and outputs a class label, one of [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class DCD(nn.Module):\n",
    "    def __init__(self, H=64, D_in=784):\n",
    "        super(DCD, self).__init__()\n",
    "        self.fc1 = nn.Linear(D_in, H)\n",
    "        self.fc2 = nn.Linear(H, H)\n",
    "        self.out = nn.Linear(H, 4)\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(out)\n",
    "        return F.softmax(self.out(out), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Classifier\n",
    "* Called h in the paper. Gives class predictions based on the latent representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, D_in=64):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.out = nn.Linear(D_in, 10)\n",
    "    def forward(self, x):\n",
    "        return F.softmax(self.out(x), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "* Creates latent representation based on data. Called g in the paper.Like in the paper, we use g_s = g_t = g, that is, we share weights between target and source representations. Model is as specified in section 4.1. See https://github.com/kuangliu/pytorch-cifar/blob/master/models/lenet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(256, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(encoder, classifier):\n",
    "    return lambda x: classifier(encoder(x))\n",
    "\n",
    "''' Pretrain the encoder and classifier as in (a) in figure 2. '''\n",
    "\n",
    "def pretrain(data, epochs=5, batch_size=128, cuda=False):\n",
    "    X_s, y_s, _, _ = data\n",
    "    test_dataloader = mnist_dataloader(train=False, cuda=cuda)\n",
    "    classifier = Classifier()\n",
    "    encoder = Encoder()\n",
    "    if cuda:\n",
    "        classifier.cuda()\n",
    "        encoder.cuda()\n",
    "    ''' Jointly optimize both encoder and classifier ''' \n",
    "    optimizer = optim.Adam(list(encoder.parameters()) + list(classifier.parameters()))\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for e in range(epochs):  \n",
    "        for _ in range(len(X_s) // batch_size):\n",
    "            inds = torch.randperm(len(X_s))[:batch_size]\n",
    "            x, y = Variable(X_s[inds]), Variable(y_s[inds])\n",
    "            optimizer.zero_grad()\n",
    "            if cuda:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "            y_pred = model_fn(encoder, classifier)(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Epoch\", e, \"Loss\", loss.data[0], \"Accuracy\", eval_on_test(test_dataloader, model_fn(encoder, classifier)))\n",
    "    return encoder, classifier\n",
    "\n",
    "''' Train the discriminator while the encoder is frozen '''\n",
    "def train_discriminator(encoder, groups, n_target_samples=2, cuda=False, epochs=20):\n",
    "    source_loader = mnist_dataloader(train=True, cuda=cuda)\n",
    "    target_loader = svhn_dataloader(train=True, cuda=cuda)\n",
    "    discriminator = DCD(D_in=128) # Takes in concatenated hidden representations\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    # Only train DCD\n",
    "    optimizer = optim.Adam(discriminator.parameters())\n",
    "    # Size of group G2, the smallest one, times the amount of groups\n",
    "    n_iters = 4 * n_target_samples\n",
    "    if cuda:\n",
    "        discriminator.cuda()\n",
    "    print(\"Training DCD\")\n",
    "    for e in range(epochs):\n",
    "        for _ in range(n_iters):    \n",
    "            # Sample a pair of samples from a group\n",
    "            group = random.choice([0, 1, 2, 3])\n",
    "            x1, x2 = groups[group][random.randint(0, len(groups[group]) - 1)]\n",
    "            x1, x2 = Variable(x1), Variable(x2)\n",
    "            if cuda:\n",
    "                x1, x2 = x1.cuda(), x2.cuda()\n",
    "            # Optimize the DCD using sample drawn\n",
    "            optimizer.zero_grad()\n",
    "            # Concatenate encoded representations\n",
    "            x_cat = torch.cat([encoder(x1.unsqueeze(0)), encoder(x2.unsqueeze(0))], 1)\n",
    "            y_pred = discriminator(x_cat)\n",
    "            # Label is the group\n",
    "            y = Variable(torch.LongTensor([group]))\n",
    "            if cuda:\n",
    "                y = y.cuda()\n",
    "            loss = -loss_fn(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Epoch\", e, \"Loss\", loss.data[0])    \n",
    "    return discriminator\n",
    "\n",
    "''' FADA Loss, as given by (4) in the paper. The minus sign is shifted because it seems to be wrong '''\n",
    "def fada_loss(y_pred_g2, g1_true, y_pred_g4, g3_true, gamma=0.2):\n",
    "    return -gamma * torch.mean(g1_true * torch.log(y_pred_g2) + g3_true * torch.log(y_pred_g4))\n",
    "\n",
    "''' Step three of the algorithm, train everything except the DCD '''\n",
    "def train(encoder, discriminator, classifier, data, groups, n_target_samples=2, cuda=False, epochs=20, batch_size=256, plot_accuracy=False):   \n",
    "    # For evaluation only\n",
    "    test_dataloader = svhn_dataloader(train=False, cuda=cuda)\n",
    "    X_s, Y_s, X_t, Y_t = data\n",
    "    G1, G2, G3, G4 = groups\n",
    "    ''' Two optimizers, one for DCD (which is frozen) and one for class training ''' \n",
    "    class_optimizer = optim.Adam(list(encoder.parameters()) + list(classifier.parameters()))\n",
    "    dcd_optimizer = optim.Adam(encoder.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    n_iters = 4 * n_target_samples   \n",
    "    if plot_accuracy:\n",
    "        accuracies = []\n",
    "    for e in range(epochs):      \n",
    "        # Shuffle data at each epoch\n",
    "        inds = torch.randperm(X_s.shape[0])\n",
    "        X_s, Y_s = X_s[inds], Y_s[inds]\n",
    "        inds = torch.randperm(X_t.shape[0])\n",
    "        X_t, Y_t = X_t[inds], Y_t[inds]\n",
    "        g2_one, g2_two = into_tensor(G2, into_vars=True)\n",
    "        g4_one, g4_two = into_tensor(G4, into_vars=True)\n",
    "        inds = torch.randperm(g2_one.shape[0])\n",
    "        if cuda:\n",
    "            inds = inds.cuda()\n",
    "        g2_one, g2_two, g4_one, g4_two = g2_one[inds], g2_two[inds], g4_one[inds], g4_two[inds]\n",
    "        for _ in range(n_iters):           \n",
    "            class_optimizer.zero_grad()\n",
    "            dcd_optimizer.zero_grad()\n",
    "            # Evaluate source predictions\n",
    "            inds = torch.randperm(X_s.shape[0])[:batch_size]\n",
    "            x_s, y_s = Variable(X_s[inds]), Variable(Y_s[inds])\n",
    "            if cuda:\n",
    "                x_s, y_s = x_s.cuda(), y_s.cuda()\n",
    "            y_pred_s = model_fn(encoder, classifier)(x_s)            \n",
    "            # Evaluate target predictions\n",
    "            ind = random.randint(0, X_t.shape[0] - 1)\n",
    "            x_t, y_t = Variable(X_t[ind].unsqueeze(0)), Variable(torch.LongTensor([Y_t[ind]]))\n",
    "            if cuda:\n",
    "                x_t, y_t = x_t.cuda(), y_t.cuda()\n",
    "            y_pred_t = model_fn(encoder, classifier)(x_t)\n",
    "            # Evaluate groups       \n",
    "            x1, x2 = encoder(g2_one), encoder(g2_two)\n",
    "            y_pred_g2 = discriminator(torch.cat([x1, x2], 1))\n",
    "            g1_true = 1\n",
    "            x1, x2 = encoder(g4_one), encoder(g4_two)\n",
    "            y_pred_g4 = discriminator(torch.cat([x1, x2], 1))\n",
    "            g3_true = 3\n",
    "            # Evaluate loss\n",
    "            # This is the full loss given by (5) in the paper\n",
    "            loss = fada_loss(y_pred_g2, g1_true, y_pred_g4, g3_true) + loss_fn(y_pred_s, y_s) + loss_fn(y_pred_t, y_t)\n",
    "            loss.backward()\n",
    "            class_optimizer.step()\n",
    "        acc = eval_on_test(test_dataloader, model_fn(encoder, classifier))\n",
    "        print(\"Epoch\", e, \"Loss\", loss.data[0], \"Accuracy\", acc)\n",
    "        if plot_accuracy:\n",
    "            accuracies.append(acc)\n",
    "    if plot_accuracy:\n",
    "        plt.plot(range(len(accuracies)), accuracies)\n",
    "        plt.title(\"SVHN test accuracy\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_target_samples = 7\n",
    "plot_accuracy = True\n",
    "cuda = torch.cuda.is_available()\n",
    "groups, data = sample_groups(n_target_samples=n_target_samples)  \n",
    "encoder, classifier = pretrain(data, cuda=cuda, epochs=20)\n",
    "discriminator = train_discriminator(encoder, groups, n_target_samples=n_target_samples, epochs=50, cuda=cuda)\n",
    "train(encoder, discriminator, classifier, data, groups, n_target_samples=n_target_samples, cuda=cuda, epochs=150, plot_accuracy=plot_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用训练好的网络"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
