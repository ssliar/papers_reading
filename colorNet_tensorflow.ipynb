{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ColorNet implement in tensorflow（非GAN）提取预训练网络\n",
    "* environment: tensorflow0.12\n",
    "* datasets:自己构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作\n",
    "### 导入有用包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf   \n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from batchnorm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读入数据以及VGG网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"./224/*.jpg\")\n",
    "with open(\"vgg16-20160129.tfmodel\", mode='rb') as f:\n",
    "    fileContent = f.read()\n",
    "graph_def = tf.GraphDef()\n",
    "graph_def.ParseFromString(fileContent)\n",
    " if not os.path.exists('summary'):\n",
    "    os.mkdir('summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batchnorm function\n",
    "* A helper class for managing batch normalization state.This class is designed to simplify adding batch normalization   (http://arxiv.org/pdf/1502.03167v3.pdf) to your model by managing the state variables associated with it.                       \n",
    "     * Important use note:  The function get_assigner() returns an op that must be executed to save the updated state. A suggested way to do this is to make execution of the model optimizer force it, e.g., by:                                \n",
    "     *update_assignments = tf.group(bn1.get_assigner(),  bn2.get_assigner())                         \n",
    "     *with tf.control_dependencies([optimizer]):                                \n",
    "    optimizer = tf.group(update_assignments)      \n",
    "* Helper class that groups the normalization logic and variables.                                                                       \n",
    "      * ewma = tf.train.ExponentialMovingAverage(decay=0.99)                  \n",
    "      * bn = ConvolutionalBatchNormalizer(depth, 0.001, ewma, True)           \n",
    "      * update_assignments = bn.get_assigner()                                \n",
    "      * x = bn.normalize(y, train=training?)                                  \n",
    "      * (the output x will be batch-normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class ConvolutionalBatchNormalizer(object):\n",
    "  def __init__(self, depth, epsilon, ewma_trainer, scale_after_norm):\n",
    "    self.mean = tf.Variable(tf.constant(0.0, shape=[depth]),trainable=False)\n",
    "    self.variance = tf.Variable(tf.constant(1.0, shape=[depth]),trainable=False)\n",
    "    self.beta = tf.Variable(tf.constant(0.0, shape=[depth]))\n",
    "    self.gamma = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "    self.ewma_trainer = ewma_trainer\n",
    "    self.epsilon = epsilon\n",
    "    self.scale_after_norm = scale_after_norm\n",
    "\n",
    "  def get_assigner(self):\n",
    "    \"\"\"Returns an EWMA apply op that must be invoked after optimization.\"\"\"\n",
    "    return self.ewma_trainer.apply([self.mean, self.variance])\n",
    "\n",
    "  def normalize(self, x, train=True):\n",
    "    \"\"\"Returns a batch-normalized version of x.\"\"\"\n",
    "    if train:\n",
    "      mean, variance = tf.nn.moments(x, [0, 1, 2])\n",
    "      assign_mean = self.mean.assign(mean)\n",
    "      assign_variance = self.variance.assign(variance)\n",
    "      with tf.control_dependencies([assign_mean, assign_variance]):\n",
    "        return tf.nn.batch_norm_with_global_normalization(\n",
    "            x, mean, variance, self.beta, self.gamma,\n",
    "            self.epsilon, self.scale_after_norm)\n",
    "    else:\n",
    "      mean = self.ewma_trainer.average(self.mean)\n",
    "      variance = self.ewma_trainer.average(self.variance)\n",
    "      local_beta = tf.identity(self.beta)\n",
    "      local_gamma = tf.identity(self.gamma)\n",
    "      return tf.nn.batch_norm_with_global_normalization(\n",
    "          x, mean, variance, local_beta, local_gamma,\n",
    "          self.epsilon, self.scale_after_norm)\n",
    "\n",
    " def rgb2yuv(rgb):\n",
    "    \"\"\"\n",
    "    Convert RGB image into YUV https://en.wikipedia.org/wiki/YUV\n",
    "    \"\"\"\n",
    "    rgb2yuv_filter = tf.constant([[[[0.299, -0.169, 0.499],\n",
    "                                    [0.587, -0.331, -0.418],\n",
    "                                    [0.114, 0.499, -0.0813]]]])\n",
    "    rgb2yuv_bias = tf.constant([0., 0.5, 0.5])\n",
    "    temp = tf.nn.conv2d(rgb, rgb2yuv_filter, [1, 1, 1, 1], 'SAME')\n",
    "    temp = tf.nn.bias_add(temp, rgb2yuv_bias)\n",
    "    return temp\n",
    " \n",
    "def yuv2rgb(yuv):\n",
    "    \"\"\"\n",
    "    Convert YUV image into RGB https://en.wikipedia.org/wiki/YUV\n",
    "    \"\"\"\n",
    "    yuv = tf.multiply(yuv, 255)\n",
    "    yuv2rgb_filter = tf.constant([[[[1., 1., 1.],\n",
    "                                    [0., -0.34413999, 1.77199996],\n",
    "                                    [1.40199995, -0.71414, 0.]]]])\n",
    "    yuv2rgb_bias = tf.constant([-179.45599365, 135.45983887, -226.81599426])\n",
    "    temp = tf.nn.conv2d(yuv, yuv2rgb_filter, [1, 1, 1, 1], 'SAME')\n",
    "    temp = tf.nn.bias_add(temp, yuv2rgb_bias)\n",
    "    temp = tf.maximum(temp, tf.zeros(temp.get_shape(), dtype=tf.float32))\n",
    "    temp = tf.minimum(temp, tf.multiply(tf.ones(temp.get_shape(), dtype=tf.float32), 255))\n",
    "    temp = tf.div(temp, 255)\n",
    "    return temp\n",
    " \n",
    "def concat_images(imga, imgb):\n",
    "    \"\"\"\n",
    "    Combines two color image ndarrays side-by-side.\n",
    "    \"\"\"\n",
    "    ha, wa = imga.shape[:2]\n",
    "    hb, wb = imgb.shape[:2]\n",
    "    max_height = np.max([ha, hb])\n",
    "    total_width = wa + wb\n",
    "    new_img = np.zeros(shape=(max_height, total_width, 3), dtype=np.float32)\n",
    "    new_img[:ha, :wa] = imga\n",
    "    new_img[:hb, wa:wa + wb] = imgb\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalBatchNormalizer(object):\n",
    "    def __init__(self, depth, epsilon, ewma_trainer, scale_after_norm):\n",
    "        self.mean = tf.Variable(tf.constant(0.0, shape=[depth]), trainable=False)\n",
    "        self.variance = tf.Variable(tf.constant(1.0, shape=[depth]), trainable=False)\n",
    "        self.beta = tf.Variable(tf.constant(0.0, shape=[depth]))\n",
    "        self.gamma = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "        self.ewma_trainer = ewma_trainer\n",
    "        self.epsilon = epsilon\n",
    "        self.scale_after_norm = scale_after_norm\n",
    " \n",
    "    def get_assigner(self):\n",
    "        \"\"\"Returns an EWMA apply op that must be invoked after optimization.\"\"\"\n",
    "        return self.ewma_trainer.apply([self.mean, self.variance])\n",
    " \n",
    "    def normalize(self, x, train=True):\n",
    "        \"\"\"Returns a batch-normalized version of x.\"\"\"\n",
    "        if train is not None:\n",
    "            mean, variance = tf.nn.moments(x, [0, 1, 2])\n",
    "            assign_mean = self.mean.assign(mean)\n",
    "            assign_variance = self.variance.assign(variance)\n",
    "            with tf.control_dependencies([assign_mean, assign_variance]):\n",
    "                return tf.nn.batch_norm_with_global_normalization(x, mean, variance, self.beta, self.gamma, self.epsilon, self.scale_after_norm)\n",
    "        else:\n",
    "            mean = self.ewma_trainer.average(self.mean)\n",
    "            variance = self.ewma_trainer.average(self.variance)\n",
    "            local_beta = tf.identity(self.beta)\n",
    "            local_gamma = tf.identity(self.gamma)\n",
    "            return tf.nn.batch_norm_with_global_normalization(x, mean, variance, local_beta, local_gamma, self.epsilon, self.scale_after_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T12:16:06.383872Z",
     "start_time": "2018-03-14T12:16:06.377371Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_my_file_format(filename_queue, randomize=False):\n",
    "    reader = tf.WholeFileReader()\n",
    "    key, file = reader.read(filename_queue)\n",
    "    uint8image = tf.image.decode_jpeg(file, channels=3)\n",
    "    uint8image = tf.random_crop(uint8image, (224, 224, 3))\n",
    "    if randomize:\n",
    "        uint8image = tf.image.random_flip_left_right(uint8image)\n",
    "        uint8image = tf.image.random_flip_up_down(uint8image, seed=None)\n",
    "    float_image = tf.div(tf.cast(uint8image, tf.float32), 255)\n",
    "    return float_image\n",
    " \n",
    "def input_pipeline(filenames, batch_size, num_epochs=None):\n",
    "    filename_queue = tf.train.string_input_producer(filenames, num_epochs=num_epochs, shuffle=False)\n",
    "    example = read_my_file_format(filename_queue, randomize=False)\n",
    "    min_after_dequeue = 100\n",
    "    capacity = min_after_dequeue + 3 * batch_size\n",
    "    example_batch = tf.train.shuffle_batch([example], batch_size=batch_size, capacity=capacity, min_after_dequeue=min_after_dequeue)\n",
    "    return example_batch\n",
    "  \n",
    " \n",
    "batch_size = 1\n",
    "num_epochs = 1e+9\n",
    "colorimage = input_pipeline(filenames, batch_size, num_epochs=num_epochs)\n",
    " \n",
    "grayscale = tf.image.rgb_to_grayscale(colorimage)\n",
    "grayscale_rgb = tf.image.grayscale_to_rgb(grayscale)\n",
    "grayscale_yuv = rgb2yuv(grayscale_rgb)\n",
    "grayscale = tf.concat( [grayscale, grayscale, grayscale],3)\n",
    " \n",
    "tf.import_graph_def(graph_def, input_map={\"images\": grayscale})\n",
    "graph = tf.get_default_graph()\n",
    " \n",
    " \n",
    "phase_train = tf.placeholder(tf.bool, name='phase_train')\n",
    "# 定义神经网络\n",
    "def color_net():\n",
    "    \"\"\"\n",
    "    Network architecture http://tinyclouds.org/colorize/residual_encoder.png\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('vgg'):\n",
    "         conv1_2 = graph.get_tensor_by_name(\"import/conv1_2/Relu:0\")\n",
    "         conv2_2 = graph.get_tensor_by_name(\"import/conv2_2/Relu:0\")\n",
    "         conv3_3 = graph.get_tensor_by_name(\"import/conv3_3/Relu:0\")\n",
    "         conv4_3 = graph.get_tensor_by_name(\"import/conv4_3/Relu:0\")\n",
    " \n",
    "    # Store layers weight\n",
    "    weights = {\n",
    "        # 1x1 conv, 512 inputs, 256 outputs\n",
    "        'wc1': tf.Variable(tf.truncated_normal([1, 1, 512, 256], stddev=0.01)),\n",
    "        # 3x3 conv, 512 inputs, 128 outputs\n",
    "        'wc2': tf.Variable(tf.truncated_normal([3, 3, 256, 128], stddev=0.01)),\n",
    "        # 3x3 conv, 256 inputs, 64 outputs\n",
    "        'wc3': tf.Variable(tf.truncated_normal([3, 3, 128, 64], stddev=0.01)),\n",
    "        # 3x3 conv, 128 inputs, 3 outputs\n",
    "        'wc4': tf.Variable(tf.truncated_normal([3, 3, 64, 3], stddev=0.01)),\n",
    "        # 3x3 conv, 6 inputs, 3 outputs\n",
    "        'wc5': tf.Variable(tf.truncated_normal([3, 3, 3, 3], stddev=0.01)),\n",
    "        # 3x3 conv, 3 inputs, 2 outputs\n",
    "       'wc6': tf.Variable(tf.truncated_normal([3, 3, 3, 2], stddev=0.01)),\n",
    "       }\n",
    " \n",
    "    def batch_norm(x, depth, phase_train):\n",
    "        with tf.variable_scope('batchnorm'):\n",
    "            ewma = tf.train.ExponentialMovingAverage(decay=0.9999)\n",
    "            bn = ConvolutionalBatchNormalizer(depth, 0.001, ewma, True)\n",
    "            update_assignments = bn.get_assigner()\n",
    "            x = bn.normalize(x, train=phase_train)\n",
    "        return x\n",
    " \n",
    "    def conv2d(_X, w, sigmoid=False, bn=False):\n",
    "        with tf.variable_scope('conv2d'):\n",
    "             _X = tf.nn.conv2d(_X, w, [1, 1, 1, 1], 'SAME')\n",
    "             if bn:\n",
    "                 _X = batch_norm(_X, w.get_shape()[3], phase_train)\n",
    "             if sigmoid:\n",
    "                 return tf.sigmoid(_X)\n",
    "             else:\n",
    "                 _X = tf.nn.relu(_X)\n",
    "                 return tf.maximum(0.01 * _X, _X)\n",
    " \n",
    "    with tf.variable_scope('color_net'):\n",
    "         # Bx28x28x512 -> batch norm -> 1x1 conv = Bx28x28x256\n",
    "         conv1 = tf.nn.relu(tf.nn.conv2d(batch_norm(conv4_3, 512, phase_train), weights['wc1'], [1, 1, 1, 1], 'SAME'))\n",
    "         # upscale to 56x56x256\n",
    "         conv1 = tf.image.resize_bilinear(conv1, (56, 56))\n",
    "         conv1 = tf.add(conv1, batch_norm(conv3_3, 256, phase_train))\n",
    " \n",
    "         # Bx56x56x256-> 3x3 conv = Bx56x56x128\n",
    "         conv2 = conv2d(conv1, weights['wc2'], sigmoid=False, bn=True)\n",
    "         # upscale to 112x112x128\n",
    "         conv2 = tf.image.resize_bilinear(conv2, (112, 112))\n",
    "         conv2 = tf.add(conv2, batch_norm(conv2_2, 128, phase_train))\n",
    " \n",
    "         # Bx112x112x128 -> 3x3 conv = Bx112x112x64\n",
    "         conv3 = conv2d(conv2, weights['wc3'], sigmoid=False, bn=True)\n",
    "         # upscale to Bx224x224x64\n",
    "         conv3 = tf.image.resize_bilinear(conv3, (224, 224))\n",
    "         conv3 = tf.add(conv3, batch_norm(conv1_2, 64, phase_train))\n",
    " \n",
    "         # Bx224x224x64 -> 3x3 conv = Bx224x224x3\n",
    "         conv4 = conv2d(conv3, weights['wc4'], sigmoid=False, bn=True)\n",
    "         conv4 = tf.add(conv4, batch_norm(grayscale, 3, phase_train))\n",
    " \n",
    "         # Bx224x224x3 -> 3x3 conv = Bx224x224x3\n",
    "         conv5 = conv2d(conv4, weights['wc5'], sigmoid=False, bn=True)\n",
    "         # Bx224x224x3 -> 3x3 conv = Bx224x224x2\n",
    "         conv6 = conv2d(conv5, weights['wc6'], sigmoid=True, bn=True)\n",
    " \n",
    "    return conv6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv = tf.placeholder(tf.uint8, name='uv')\n",
    "# 训练\n",
    "def train_color_net():\n",
    "    pred = color_net()\n",
    "    pred_yuv = tf.concat( [tf.split(grayscale_yuv, 3, 3)[0], pred],3)\n",
    "    pred_rgb = yuv2rgb(pred_yuv)\n",
    " \n",
    "    colorimage_yuv = rgb2yuv(colorimage)\n",
    "    loss = tf.square(tf.subtract(pred, tf.concat( [tf.split(colorimage_yuv, 3, 3)[1], tf.split(colorimage_yuv, 3,3 )[2]],3)))\n",
    " \n",
    "    if uv == 1:\n",
    "        loss = tf.split(loss, 2,3)[0]\n",
    "    elif uv == 2:\n",
    "        loss = tf.split(loss, 2,3)[1]\n",
    "    else:\n",
    "        loss = (tf.split(loss, 2,3)[0] + tf.split(loss, 2,3)[1]) / 2\n",
    " \n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    if phase_train is not None:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(0.0001)\n",
    "        opt = optimizer.minimize(loss, global_step=global_step, gate_gradients=optimizer.GATE_NONE)\n",
    " \n",
    "    # Saver.\n",
    "    saver = tf.train.Saver()\n",
    "    sess = tf.Session()\n",
    "    # Initialize the variables.\n",
    "    sess.run(tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    " \n",
    "    # Start input enqueue threads.\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    " \n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            # Run training steps\n",
    "            training_opt = sess.run(opt, feed_dict={phase_train: True, uv: 1})\n",
    "            training_opt = sess.run(opt, feed_dict={phase_train: True, uv: 2})\n",
    " \n",
    "            step = sess.run(global_step)\n",
    " \n",
    "            if step % 1 == 0:\n",
    "                pred_, pred_rgb_, colorimage_, grayscale_rgb_, cost = sess.run([pred, pred_rgb, colorimage, grayscale_rgb, loss], feed_dict={phase_train: False, uv: 3})\n",
    "                print({\"step\": step, \"cost\": np.mean(cost)})\n",
    "                if step % 1000 == 0:\n",
    "                    summary_image = concat_images(grayscale_rgb_[0], pred_rgb_[0])\n",
    "                    summary_image = concat_images(summary_image, colorimage_[0])\n",
    "                    plt.imsave(\"summary/\" + str(step) + \"_0\", summary_image)\n",
    " \n",
    "            if step % 100000 == 99998:\n",
    "            save_path = saver.save(sess, \"color_net_model.ckpt\")\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    " \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training -- epoch limit reached')\n",
    "    finally:\n",
    "        # When done, ask the threads to stop.\n",
    "        coord.request_stop()\n",
    " \n",
    "    # Wait for threads to finish.\n",
    "    coord.join(threads)\n",
    "    sess.close()\n",
    "train_color_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
